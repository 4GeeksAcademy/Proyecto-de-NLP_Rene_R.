{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Collecting pandas\n",
                        "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
                        "Collecting regex\n",
                        "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
                        "Collecting nltk\n",
                        "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
                        "Collecting scikit-learn\n",
                        "  Using cached scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
                        "Collecting matplotlib\n",
                        "  Using cached matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
                        "Collecting wordcloud\n",
                        "  Using cached wordcloud-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
                        "Collecting pickle-mixin\n",
                        "  Using cached pickle_mixin-1.0.2-py3-none-any.whl\n",
                        "Collecting numpy>=1.23.2 (from pandas)\n",
                        "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
                        "Collecting pytz>=2020.1 (from pandas)\n",
                        "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
                        "Collecting tzdata>=2022.7 (from pandas)\n",
                        "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
                        "Collecting click (from nltk)\n",
                        "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
                        "Collecting joblib (from nltk)\n",
                        "  Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
                        "Collecting tqdm (from nltk)\n",
                        "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
                        "Collecting scipy>=1.6.0 (from scikit-learn)\n",
                        "  Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
                        "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
                        "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
                        "Collecting contourpy>=1.0.1 (from matplotlib)\n",
                        "  Using cached contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
                        "Collecting cycler>=0.10 (from matplotlib)\n",
                        "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
                        "Collecting fonttools>=4.22.0 (from matplotlib)\n",
                        "  Using cached fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
                        "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
                        "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
                        "Collecting pillow>=8 (from matplotlib)\n",
                        "  Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
                        "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
                        "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
                        "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
                        "Installing collected packages: pytz, pickle-mixin, tzdata, tqdm, threadpoolctl, regex, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, cycler, click, scipy, pandas, nltk, contourpy, scikit-learn, matplotlib, wordcloud\n",
                        "Successfully installed click-8.1.8 contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 joblib-1.5.0 kiwisolver-1.4.8 matplotlib-3.10.3 nltk-3.9.1 numpy-2.2.5 pandas-2.2.3 pickle-mixin-1.0.2 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 regex-2024.11.6 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2 wordcloud-1.9.4\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!pip install pandas regex nltk scikit-learn matplotlib wordcloud pickle-mixin\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dimensiones del dataset: (2999, 2)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Cargar CSV directamente desde GitHub\n",
                "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv\")\n",
                "\n",
                "# Ver dimensiones y primeras filas\n",
                "print(\"Dimensiones del dataset:\", df.shape)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
                        "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
                        "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>tokens</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>http briefingday list manage com unsubscribe</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>http www hvper com</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>http briefingday com vnif</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>http briefingday com mcommentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>http briefingday com fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  \\\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...   \n",
                            "1                             https://www.hvper.com/   \n",
                            "2                 https://briefingday.com/m/v4n3i4f3   \n",
                            "3   https://briefingday.com/n/20200618/m#commentform   \n",
                            "4                        https://briefingday.com/fan   \n",
                            "\n",
                            "                                         tokens  is_spam  \n",
                            "0  http briefingday list manage com unsubscribe     True  \n",
                            "1                            http www hvper com     True  \n",
                            "2                     http briefingday com vnif     True  \n",
                            "3             http briefingday com mcommentform    False  \n",
                            "4                      http briefingday com fan     True  "
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import regex as re\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from nltk import download\n",
                "\n",
                "# Descargar recursos de NLTK necesarios\n",
                "download(\"stopwords\")\n",
                "download(\"wordnet\")\n",
                "\n",
                "# Inicializar herramientas\n",
                "stop_words = set(stopwords.words(\"english\"))\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "# Funci√≥n de preprocesamiento\n",
                "def preprocess_url(url):\n",
                "    # Convertir a min√∫sculas\n",
                "    url = url.lower()\n",
                "    \n",
                "    # Reemplazar signos comunes por espacio\n",
                "    url = re.sub(r\"[\\/\\.\\-_=:\\?&%]+\", \" \", url)\n",
                "\n",
                "    # Eliminar caracteres no alfab√©ticos\n",
                "    url = re.sub(r\"[^a-z ]+\", \"\", url)\n",
                "\n",
                "    # Tokenizar, lematizar y quitar stopwords/palabras cortas\n",
                "    tokens = url.split()\n",
                "    tokens = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
                "    tokens = [tok for tok in tokens if tok not in stop_words and len(tok) > 2]\n",
                "\n",
                "    return \" \".join(tokens)\n",
                "\n",
                "# Aplicar la transformaci√≥n\n",
                "df[\"tokens\"] = df[\"url\"].apply(preprocess_url)\n",
                "\n",
                "# Ver resultado\n",
                "df[[\"url\", \"tokens\", \"is_spam\"]].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Forma del conjunto de entrenamiento: (2399, 1369)\n",
                        "Forma del conjunto de prueba: (600, 1369)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Unir tokens en una cadena para cada fila\n",
                "corpus = df[\"tokens\"].values\n",
                "\n",
                "# Vectorizar con TF-IDF\n",
                "vectorizer = TfidfVectorizer(max_features=5000, max_df=0.8, min_df=3)\n",
                "X = vectorizer.fit_transform(corpus).toarray()\n",
                "\n",
                "# Etiquetas: convertir booleanos a enteros (True ‚Üí 1, False ‚Üí 0)\n",
                "y = df[\"is_spam\"].astype(int)\n",
                "\n",
                "# Divisi√≥n en conjunto de entrenamiento y prueba\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(\"Forma del conjunto de entrenamiento:\", X_train.shape)\n",
                "print(\"Forma del conjunto de prueba:\", X_test.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Accuracy: 0.92\n",
                        "\n",
                        " Reporte de Clasificaci√≥n:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.93      0.97      0.95       455\n",
                        "           1       0.89      0.77      0.82       145\n",
                        "\n",
                        "    accuracy                           0.92       600\n",
                        "   macro avg       0.91      0.87      0.89       600\n",
                        "weighted avg       0.92      0.92      0.92       600\n",
                        "\n",
                        "\n",
                        " Matriz de Confusi√≥n:\n",
                        " [[441  14]\n",
                        " [ 34 111]]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "# Inicializar y entrenar el modelo SVM con kernel lineal\n",
                "model = SVC(kernel=\"linear\", random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Predecir sobre el conjunto de prueba\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Evaluar el modelo\n",
                "print(\" Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "print(\"\\n Reporte de Clasificaci√≥n:\\n\", classification_report(y_test, y_pred))\n",
                "print(\"\\n Matriz de Confusi√≥n:\\n\", confusion_matrix(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
                        "üîß Mejores par√°metros: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
                        "Accuracy optimizado: 0.95\n",
                        "\n",
                        " Reporte optimizado:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.96      0.97      0.97       455\n",
                        "           1       0.91      0.88      0.89       145\n",
                        "\n",
                        "    accuracy                           0.95       600\n",
                        "   macro avg       0.94      0.92      0.93       600\n",
                        "weighted avg       0.95      0.95      0.95       600\n",
                        "\n",
                        "\n",
                        " Matriz de confusi√≥n optimizada:\n",
                        " [[443  12]\n",
                        " [ 18 127]]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# Definir el modelo base\n",
                "svc = SVC()\n",
                "\n",
                "# Definir el espacio de b√∫squeda de hiperpar√°metros\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10],\n",
                "    'kernel': ['linear', 'rbf'],\n",
                "    'gamma': ['scale', 'auto']\n",
                "}\n",
                "\n",
                "# GridSearch con validaci√≥n cruzada de 5 folds\n",
                "grid_search = GridSearchCV(\n",
                "    svc, param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1\n",
                ")\n",
                "\n",
                "# Ajustar el modelo\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "# Mostrar mejores par√°metros encontrados\n",
                "print(\"üîß Mejores par√°metros:\", grid_search.best_params_)\n",
                "\n",
                "# Evaluar el mejor modelo en el test set\n",
                "best_model = grid_search.best_estimator_\n",
                "y_pred_opt = best_model.predict(X_test)\n",
                "\n",
                "print(\"Accuracy optimizado:\", accuracy_score(y_test, y_pred_opt))\n",
                "print(\"\\n Reporte optimizado:\\n\", classification_report(y_test, y_pred_opt))\n",
                "print(\"\\n Matriz de confusi√≥n optimizada:\\n\", confusion_matrix(y_test, y_pred_opt))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Modelo guardado como 'svm_url_spam_rbf_c10.sav'\n"
                    ]
                }
            ],
            "source": [
                "import pickle\n",
                "\n",
                "# Guardar el modelo en archivo .sav\n",
                "filename = \"svm_url_spam_rbf_c10.sav\"\n",
                "with open(filename, \"wb\") as f:\n",
                "    pickle.dump(best_model, f)\n",
                "\n",
                "print(f\"Modelo guardado como '{filename}'\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
